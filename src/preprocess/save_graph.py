import pickle
import os
import pandas as pd
import networkx as nx
from make_graph_dataset import build_aba_graph

def save_graph_pickle(graph: nx.DiGraph, filename: str):
    """ã‚°ãƒ©ãƒ•ã‚’Pickleå½¢å¼ã§ä¿å­˜"""
    # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs("data/output", exist_ok=True)
    
    filepath = f"data/output/{filename}.pkl"
    
    with open(filepath, 'wb') as f:
        pickle.dump(graph, f)
    
    print(f"âœ“ ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
    print(f"  - ãƒãƒ¼ãƒ‰æ•°: {graph.number_of_nodes()}")
    print(f"  - ã‚¨ãƒƒã‚¸æ•°: {graph.number_of_edges()}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚‚è¡¨ç¤º
    file_size = os.path.getsize(filepath)
    print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes")
    
    return filepath

if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    aba_file_path = "data/input/Original ABA Dataset for Version 2 [June 15] - 1. hotel in Larnaca-Cyprus - Topic.csv"
    cols = ['ReviewID', 'Title', 'Topic', 'Pos/Neg', 'Claim', 'Head',
    'Body 1', 'Body 2', 'Body 3', 'Body 4', 'Body 5', 'Body 6', 'Body 7',
    'Body 8', 'Body 9', 'Body 10', 'Body 11', 'Body 12', 'Body 13',
    'Body 14', 'Body 15', 'Cont. Body 1', 'Cont. Body 2', 'Cont. Body 3',
    'Cont. Body 4', 'Cont. Body 5', 'Cont. Body 6', 'Cont. Body 7', 
    'Cont. Body 8', 'Cont. Body 9', 'Cont. Body 10', 'Cont. Body 11',
    'Cont. Body 12', 'Cont. Body 13', 'Cont. Body 14', 'Cont. Body 15',]
    aba = pd.read_csv(aba_file_path, usecols=cols)
    aba_room = aba[aba['Topic'] == 'Room']
    
    # 2ã¤ã®contraãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    contra_file_path_1 = "data/output/Silver_Room_ContP_BodyN_4omini.csv"
    contra_file_path_2 = "data/output/Silver_Room_ContN_BodyP_4omini.csv"
    
    print(f"ğŸ“‚ Contraãƒ•ã‚¡ã‚¤ãƒ«1ã‚’èª­ã¿è¾¼ã¿: {contra_file_path_1}")
    contra_1 = pd.read_csv(contra_file_path_1)
    print(f"  - ãƒ‡ãƒ¼ã‚¿æ•°: {len(contra_1)} è¡Œ")
    
    print(f"ğŸ“‚ Contraãƒ•ã‚¡ã‚¤ãƒ«2ã‚’èª­ã¿è¾¼ã¿: {contra_file_path_2}")
    contra_2 = pd.read_csv(contra_file_path_2)
    print(f"  - ãƒ‡ãƒ¼ã‚¿æ•°: {len(contra_2)} è¡Œ")
    
    # 2ã¤ã®contraãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
    contra_combined = pd.concat([contra_1, contra_2], ignore_index=True)
    print(f"ğŸ“Š çµ±åˆå¾Œã®ãƒ‡ãƒ¼ã‚¿æ•°: {len(contra_combined)} è¡Œ")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
    duplicates = contra_combined.duplicated().sum()
    if duplicates > 0:
        print(f"âš ï¸  é‡è¤‡ãƒ‡ãƒ¼ã‚¿: {duplicates} è¡Œ")
        contra_combined = contra_combined.drop_duplicates().reset_index(drop=True)
        print(f"âœ“ é‡è¤‡é™¤å»å¾Œ: {len(contra_combined)} è¡Œ")
    else:
        print("âœ“ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãªã—")

    # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    aba_graph_room = build_aba_graph(aba_room, contra_combined)

    # ã‚°ãƒ©ãƒ•ä¿å­˜ï¼ˆçµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’åæ˜ ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
    saved_file = save_graph_pickle(aba_graph_room, "aba_graph_staff_combined")
    print(f"\nä¿å­˜å®Œäº†: {saved_file}")
    print(f"ğŸ“ˆ çµ±åˆã•ã‚ŒãŸcontraãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸã‚°ãƒ©ãƒ•ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")
