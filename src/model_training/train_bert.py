"""
BERT „É¢„Éá„É´Â≠¶ÁøíÁî®„ÅÆ„É¢„Ç∏„É•„Éº„É´
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import time
import numpy as np


class ABADataset(Dataset):
    """
    ABA Link PredictionÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà
    """
    def __init__(self, edges, all_nodes):
        """
        Args:
            edges: List of ((assumption, proposition), label)
            all_nodes: List of all node texts
        """
        self.edges = edges
        self.all_nodes = all_nodes
        
    def __len__(self):
        return len(self.edges)
    
    def __getitem__(self, idx):
        (assumption, proposition), label = self.edges[idx]
        return {
            'assumption': assumption,
            'proposition': proposition,
            'label': float(label)
        }


def train_bert_model(model, train_loader, val_loader, num_epochs=20, lr=1e-3, 
                     device='cpu', model_name="BERT", early_stopping_patience=5,
                     verbose=True, scheduler_config=None):
    """
    BERT„É¢„Éá„É´„ÅÆÂ≠¶ÁøíÔºàË©≥Á¥∞„Å™Â≠¶ÁøíÈÅéÁ®ãË®òÈå≤‰ªò„ÅçÔºâ
    
    Args:
        model: BERT„É¢„Éá„É´
        train_loader: Ë®ìÁ∑¥„Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº
        val_loader: Ê§úË®º„Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº
        num_epochs: „Ç®„Éù„ÉÉ„ÇØÊï∞
        lr: Â≠¶ÁøíÁéá
        device: Ë®àÁÆó„Éá„Éê„Ç§„Çπ
        model_name: „É¢„Éá„É´ÂêçÔºàË°®Á§∫Áî®Ôºâ
        early_stopping_patience: Êó©ÊúüÁµÇ‰∫Ü„ÅÆ„Åü„ÇÅ„ÅÆÂæÖÊ©ü„Ç®„Éù„ÉÉ„ÇØÊï∞
        verbose: Ë©≥Á¥∞Ë°®Á§∫„Éï„É©„Ç∞
        scheduler_config: „Çπ„Ç±„Ç∏„É•„Éº„É©„ÉºË®≠ÂÆö (dict or None)
    
    Returns:
        dict: Â≠¶ÁøíÈÅéÁ®ã„ÅÆÊÉÖÂ†±
    """
    model = model.to(device)
    
    if verbose:
        # „É¢„Éá„É´„Éë„É©„É°„Éº„ÇøÊÉÖÂ†±Ë°®Á§∫
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"\nüìä {model_name} „Éë„É©„É°„Éº„ÇøÊÉÖÂ†±:")
        print(f"  Á∑è„Éë„É©„É°„Éº„ÇøÊï∞: {total_params:,}")
        print(f"  Â≠¶ÁøíÂèØËÉΩ„Éë„É©„É°„Éº„ÇøÊï∞: {trainable_params:,}")
        print(f"  Âõ∫ÂÆö„Éë„É©„É°„Éº„ÇøÊï∞: {total_params - trainable_params:,}")
        print(f"  Â≠¶ÁøíÂØæË±°ÊØîÁéá: {trainable_params/total_params*100:.2f}%")
        
        # Â≠¶ÁøíË®≠ÂÆöË°®Á§∫
        print(f"\n‚öôÔ∏è  {model_name} Â≠¶ÁøíË®≠ÂÆö:")
        print(f"  „Ç®„Éù„ÉÉ„ÇØÊï∞: {num_epochs}")
        print(f"  Â≠¶ÁøíÁéá: {lr}")
        print(f"  „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: {train_loader.batch_size if hasattr(train_loader, 'batch_size') else 'ÂèØÂ§â'}")
        print(f"  ÊúÄÈÅ©ÂåñÊâãÊ≥ï: Adam")
        print(f"  Êó©ÊúüÁµÇ‰∫Ü: patience={early_stopping_patience}")
        print("-" * 50)
    
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)
    
    # „Çπ„Ç±„Ç∏„É•„Éº„É©„Éº„ÅÆË®≠ÂÆö
    scheduler = None
    if scheduler_config:
        if scheduler_config['type'] == 'StepLR':
            scheduler = torch.optim.lr_scheduler.StepLR(
                optimizer, 
                step_size=scheduler_config.get('step_size', 5),
                gamma=scheduler_config.get('gamma', 0.7)
            )
            if verbose:
                print(f"  „Çπ„Ç±„Ç∏„É•„Éº„É©„Éº: StepLR (step_size={scheduler_config['step_size']}, gamma={scheduler_config['gamma']})")
    
    best_val_loss = float('inf')
    patience_counter = 0
    
    train_losses = []
    val_losses = []
    
    if verbose:
        print(f"\nüöÄ {model_name} Â≠¶ÁøíÈñãÂßã...")
        print("=" * 60)
    
    start_time = time.time()
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        
        # Training phase
        model.train()
        total_loss = 0
        batch_count = 0
        
        for batch_idx, batch in enumerate(train_loader):
            try:
                optimizer.zero_grad()
                
                assumptions = batch['assumption']
                propositions = batch['proposition']
                labels = batch['label'].to(device)
                
                # „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                if len(assumptions) == 0:
                    continue
                
                outputs = model(assumptions, propositions)
                loss = criterion(outputs, labels)
                
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                total_loss += loss.item()
                batch_count += 1
                
                # ÈÄ≤ÊçóË°®Á§∫Ôºà10„Éê„ÉÉ„ÉÅ„Åî„Å®Ôºâ
                if verbose and batch_idx % 10 == 0 and batch_idx > 0:
                    current_lr = optimizer.param_groups[0]['lr']
                    print(f"    Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}: "
                          f"Loss = {loss.item():.4f}, LR = {current_lr:.2e}")
                
            except Exception as batch_error:
                if verbose:
                    print(f"    ‚ö†Ô∏è Epoch {epoch+1}, Batch {batch_idx} Âá¶ÁêÜ„Ç®„É©„Éº: {batch_error}")
                continue
        
        # Validation phase
        model.eval()
        val_loss = 0
        val_batch_count = 0
        
        with torch.no_grad():
            for batch in val_loader:
                try:
                    assumptions = batch['assumption']
                    propositions = batch['proposition']
                    labels = batch['label'].to(device)
                    
                    if len(assumptions) == 0:
                        continue
                    
                    outputs = model(assumptions, propositions)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item()
                    val_batch_count += 1
                    
                except Exception as val_error:
                    if verbose:
                        print(f"    ‚ö†Ô∏è „Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Ç®„É©„Éº: {val_error}")
                    continue
        
        # ÊêçÂ§±Ë®àÁÆó
        avg_train_loss = total_loss / batch_count if batch_count > 0 else 0.0
        avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else 0.0
        
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        
        # Êó©ÊúüÁµÇ‰∫ÜÂà§ÂÆö
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            if verbose:
                print(f"    ‚úÖ Êñ∞„Åó„ÅÑÊúÄËâØ„É¢„Éá„É´ (Val Loss: {avg_val_loss:.4f})")
        else:
            patience_counter += 1
            if verbose:
                print(f"    ‚è≥ ÊîπÂñÑ„Å™„Åó {patience_counter}/{early_stopping_patience} „Ç®„Éù„ÉÉ„ÇØ")
        
        # „Çπ„Ç±„Ç∏„É•„Éº„É©„Éº„Çπ„ÉÜ„ÉÉ„Éó
        if scheduler:
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']
            if verbose:
                print(f"    üìâ Â≠¶ÁøíÁéáÊõ¥Êñ∞: {current_lr:.2e}")
        
        epoch_time = time.time() - epoch_start_time
        
        # „Ç®„Éù„ÉÉ„ÇØÁµêÊûúË°®Á§∫
        if verbose:
            print(f"    üìä Epoch {epoch+1}/{num_epochs} ÂÆå‰∫Ü: "
                  f"Train Loss = {avg_train_loss:.4f}, "
                  f"Val Loss = {avg_val_loss:.4f}, "
                  f"Time = {epoch_time:.2f}s")
            print("-" * 60)
        
        # Êó©ÊúüÁµÇ‰∫Ü„ÉÅ„Çß„ÉÉ„ÇØ
        if patience_counter >= early_stopping_patience:
            if verbose:
                print(f"    üõë Êó©ÊúüÁµÇ‰∫Ü: {early_stopping_patience} „Ç®„Éù„ÉÉ„ÇØÈÄ£Á∂ö„ÅßÊîπÂñÑ„Å™„Åó")
                print(f"    üìà ÊúÄËâØÊ§úË®ºÊêçÂ§±: {best_val_loss:.4f} „ÅßÂ≠¶ÁøíÁµÇ‰∫Ü")
            break
    
    total_time = time.time() - start_time
    
    if verbose:
        print(f"\n‚úÖ {model_name} Â≠¶ÁøíÂÆå‰∫Ü!")
        print(f"   Á∑èÂ≠¶ÁøíÊôÇÈñì: {total_time:.2f}Áßí")
        print(f"   ÊúÄÁµÇË®ìÁ∑¥ÊêçÂ§±: {train_losses[-1]:.4f}")
        print(f"   ÊúÄÁµÇÊ§úË®ºÊêçÂ§±: {val_losses[-1]:.4f}")
        print(f"   ÊúÄËâØÊ§úË®ºÊêçÂ§±: {best_val_loss:.4f}")
    
    # Â≠¶ÁøíÁµêÊûú„Çí„Åæ„Å®„ÇÅ„Å¶Ëøî„Åô
    training_info = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'total_time': total_time,
        'best_val_loss': best_val_loss,
        'final_train_loss': train_losses[-1],
        'final_val_loss': val_losses[-1],
        'model_name': model_name,
        'num_epochs': len(train_losses),
        'learning_rate': lr
    }
    
    return training_info


def evaluate_bert_model(model, test_loader, device='cpu'):
    """
    BERT„É¢„Éá„É´„ÅÆË©ï‰æ°
    
    Args:
        model: BERT„É¢„Éá„É´
        test_loader: „ÉÜ„Çπ„Éà„Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº
        device: Ë®àÁÆó„Éá„Éê„Ç§„Çπ
    
    Returns:
        dict: Ë©ï‰æ°„É°„Éà„É™„ÇØ„Çπ
        np.array: ‰∫àÊ∏¨Á¢∫Áéá
    """
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
    
    model = model.to(device)
    model.eval()
    
    all_predictions = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for batch in test_loader:
            try:
                assumptions = batch['assumption']
                propositions = batch['proposition']
                labels = batch['label'].to(device)
                
                if len(assumptions) == 0:
                    continue
                
                outputs = model(assumptions, propositions)
                probs = torch.sigmoid(outputs)
                predictions = (probs > 0.5).float()
                
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                all_probs.extend(probs.cpu().numpy())
                
            except Exception as e:
                print(f"‚ö†Ô∏è Ë©ï‰æ°‰∏≠„ÅÆ„Ç®„É©„Éº: {e}")
                continue
    
    if len(all_labels) == 0:
        return {
            'accuracy': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'f1': 0.0,
            'auc': 0.0
        }, np.array([])
    
    # Calculate metrics
    accuracy = accuracy_score(all_labels, all_predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_labels, all_predictions, average='binary', zero_division=0
    )
    
    try:
        auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0
    except:
        auc = 0.0
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc
    }
    
    return metrics, np.array(all_probs)

