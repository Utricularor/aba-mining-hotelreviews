"""
BERT ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import time
import numpy as np


class ABADataset(Dataset):
    """
    ABA Link Predictionç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    """
    def __init__(self, edges, all_nodes):
        """
        Args:
            edges: List of ((assumption, proposition), label)
            all_nodes: List of all node texts
        """
        self.edges = edges
        self.all_nodes = all_nodes
        
    def __len__(self):
        return len(self.edges)
    
    def __getitem__(self, idx):
        (assumption, proposition), label = self.edges[idx]
        return {
            'assumption': assumption,
            'proposition': proposition,
            'label': float(label)
        }


def train_bert_model(model, train_loader, val_loader, num_epochs=20, lr=1e-3, 
                     device='cpu', model_name="BERT", early_stopping_patience=5,
                     verbose=True, scheduler_config=None):
    """
    BERTãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ï¼ˆè©³ç´°ãªå­¦ç¿’éŽç¨‹è¨˜éŒ²ä»˜ãï¼‰
    
    Args:
        model: BERTãƒ¢ãƒ‡ãƒ«
        train_loader: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        val_loader: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        num_epochs: ã‚¨ãƒãƒƒã‚¯æ•°
        lr: å­¦ç¿’çŽ‡
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆè¡¨ç¤ºç”¨ï¼‰
        early_stopping_patience: æ—©æœŸçµ‚äº†ã®ãŸã‚ã®å¾…æ©Ÿã‚¨ãƒãƒƒã‚¯æ•°
        verbose: è©³ç´°è¡¨ç¤ºãƒ•ãƒ©ã‚°
        scheduler_config: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š (dict or None)
    
    Returns:
        dict: å­¦ç¿’éŽç¨‹ã®æƒ…å ±
    """
    model = model.to(device)
    
    if verbose:
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±è¡¨ç¤º
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"\nðŸ“Š {model_name} ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±:")
        print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"  å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
        print(f"  å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params - trainable_params:,}")
        print(f"  å­¦ç¿’å¯¾è±¡æ¯”çŽ‡: {trainable_params/total_params*100:.2f}%")
        
        # å­¦ç¿’è¨­å®šè¡¨ç¤º
        print(f"\nâš™ï¸  {model_name} å­¦ç¿’è¨­å®š:")
        print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {num_epochs}")
        print(f"  å­¦ç¿’çŽ‡: {lr}")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {train_loader.batch_size if hasattr(train_loader, 'batch_size') else 'å¯å¤‰'}")
        print(f"  æœ€é©åŒ–æ‰‹æ³•: Adam")
        print(f"  æ—©æœŸçµ‚äº†: patience={early_stopping_patience}")
        print("-" * 50)
    
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®š
    scheduler = None
    if scheduler_config:
        if scheduler_config['type'] == 'StepLR':
            scheduler = torch.optim.lr_scheduler.StepLR(
                optimizer, 
                step_size=scheduler_config.get('step_size', 5),
                gamma=scheduler_config.get('gamma', 0.7)
            )
            if verbose:
                print(f"  ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼: StepLR (step_size={scheduler_config['step_size']}, gamma={scheduler_config['gamma']})")
    
    best_val_loss = float('inf')
    patience_counter = 0
    
    train_losses = []
    val_losses = []
    
    if verbose:
        print(f"\nðŸš€ {model_name} å­¦ç¿’é–‹å§‹...")
        print("=" * 60)
    
    start_time = time.time()
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        
        # Training phase
        model.train()
        total_loss = 0
        batch_count = 0
        
        for batch_idx, batch in enumerate(train_loader):
            try:
                optimizer.zero_grad()
                
                assumptions = batch['assumption']
                propositions = batch['proposition']
                labels = batch['label'].to(device)
                
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
                if len(assumptions) == 0:
                    continue
                
                outputs = model(assumptions, propositions)
                loss = criterion(outputs, labels)
                
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                total_loss += loss.item()
                batch_count += 1
                
                # é€²æ—è¡¨ç¤ºï¼ˆ10ãƒãƒƒãƒã”ã¨ï¼‰
                if verbose and batch_idx % 10 == 0 and batch_idx > 0:
                    current_lr = optimizer.param_groups[0]['lr']
                    print(f"    Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}: "
                          f"Loss = {loss.item():.4f}, LR = {current_lr:.2e}")
                
            except Exception as batch_error:
                if verbose:
                    print(f"    âš ï¸ Epoch {epoch+1}, Batch {batch_idx} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {batch_error}")
                continue
        
        # Validation phase
        model.eval()
        val_loss = 0
        val_batch_count = 0
        
        with torch.no_grad():
            for batch in val_loader:
                try:
                    assumptions = batch['assumption']
                    propositions = batch['proposition']
                    labels = batch['label'].to(device)
                    
                    if len(assumptions) == 0:
                        continue
                    
                    outputs = model(assumptions, propositions)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item()
                    val_batch_count += 1
                    
                except Exception as val_error:
                    if verbose:
                        print(f"    âš ï¸ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {val_error}")
                    continue
        
        # æå¤±è¨ˆç®—
        avg_train_loss = total_loss / batch_count if batch_count > 0 else 0.0
        avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else 0.0
        
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        
        # æ—©æœŸçµ‚äº†åˆ¤å®š
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            if verbose:
                print(f"    âœ… æ–°ã—ã„æœ€è‰¯ãƒ¢ãƒ‡ãƒ« (Val Loss: {avg_val_loss:.4f})")
        else:
            patience_counter += 1
            if verbose:
                print(f"    â³ æ”¹å–„ãªã— {patience_counter}/{early_stopping_patience} ã‚¨ãƒãƒƒã‚¯")
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—
        if scheduler:
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']
            if verbose:
                print(f"    ðŸ“‰ å­¦ç¿’çŽ‡æ›´æ–°: {current_lr:.2e}")
        
        epoch_time = time.time() - epoch_start_time
        
        # ã‚¨ãƒãƒƒã‚¯çµæžœè¡¨ç¤º
        if verbose:
            print(f"    ðŸ“Š Epoch {epoch+1}/{num_epochs} å®Œäº†: "
                  f"Train Loss = {avg_train_loss:.4f}, "
                  f"Val Loss = {avg_val_loss:.4f}, "
                  f"Time = {epoch_time:.2f}s")
            print("-" * 60)
        
        # æ—©æœŸçµ‚äº†ãƒã‚§ãƒƒã‚¯
        if patience_counter >= early_stopping_patience:
            if verbose:
                print(f"    ðŸ›‘ æ—©æœŸçµ‚äº†: {early_stopping_patience} ã‚¨ãƒãƒƒã‚¯é€£ç¶šã§æ”¹å–„ãªã—")
                print(f"    ðŸ“ˆ æœ€è‰¯æ¤œè¨¼æå¤±: {best_val_loss:.4f} ã§å­¦ç¿’çµ‚äº†")
            break
    
    total_time = time.time() - start_time
    
    if verbose:
        print(f"\nâœ… {model_name} å­¦ç¿’å®Œäº†!")
        print(f"   ç·å­¦ç¿’æ™‚é–“: {total_time:.2f}ç§’")
        print(f"   æœ€çµ‚è¨“ç·´æå¤±: {train_losses[-1]:.4f}")
        print(f"   æœ€çµ‚æ¤œè¨¼æå¤±: {val_losses[-1]:.4f}")
        print(f"   æœ€è‰¯æ¤œè¨¼æå¤±: {best_val_loss:.4f}")
    
    # å­¦ç¿’çµæžœã‚’ã¾ã¨ã‚ã¦è¿”ã™
    training_info = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'total_time': total_time,
        'best_val_loss': best_val_loss,
        'final_train_loss': train_losses[-1],
        'final_val_loss': val_losses[-1],
        'model_name': model_name,
        'num_epochs': len(train_losses),
        'learning_rate': lr
    }
    
    return training_info


def evaluate_bert_model(model, test_loader, device='cpu'):
    """
    BERTãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    
    Args:
        model: BERTãƒ¢ãƒ‡ãƒ«
        test_loader: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
    
    Returns:
        dict: è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        np.array: äºˆæ¸¬ç¢ºçŽ‡
    """
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
    
    model = model.to(device)
    model.eval()
    
    all_predictions = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for batch in test_loader:
            try:
                assumptions = batch['assumption']
                propositions = batch['proposition']
                labels = batch['label'].to(device)
                
                if len(assumptions) == 0:
                    continue
                
                outputs = model(assumptions, propositions)
                probs = torch.sigmoid(outputs)
                predictions = (probs > 0.5).float()
                
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                all_probs.extend(probs.cpu().numpy())
                
            except Exception as e:
                print(f"âš ï¸ è©•ä¾¡ä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}")
                continue
    
    if len(all_labels) == 0:
        return {
            'accuracy': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'f1': 0.0,
            'auc': 0.0
        }, np.array([])
    
    # Calculate metrics
    accuracy = accuracy_score(all_labels, all_predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_labels, all_predictions, average='binary', zero_division=0
    )
    
    try:
        auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0
    except:
        auc = 0.0
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc
    }
    
    return metrics, np.array(all_probs)

