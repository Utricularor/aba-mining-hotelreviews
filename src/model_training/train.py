import torch
import torch.nn as nn
import time

def train_model(model, data, train_edges, node_to_idx, num_epochs=100, lr=0.001, 
                model_name="R-GCN", verbose=True, validation_edges=None):
    """
    æ‹¡å¼µã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–¢æ•°ï¼ˆè©³ç´°ãªå­¦ç¿’éç¨‹è¨˜éŒ²ä»˜ãï¼‰
    
    Args:
        model: å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        data: ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
        train_edges: è¨“ç·´ã‚¨ãƒƒã‚¸
        node_to_idx: ãƒãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°
        num_epochs: ã‚¨ãƒãƒƒã‚¯æ•°
        lr: å­¦ç¿’ç‡
        model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆè¡¨ç¤ºç”¨ï¼‰
        verbose: è©³ç´°è¡¨ç¤ºãƒ•ãƒ©ã‚°
        validation_edges: æ¤œè¨¼ã‚¨ãƒƒã‚¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        dict: å­¦ç¿’éç¨‹ã®æƒ…å ±ï¼ˆæå¤±ã€æ™‚é–“ãªã©ï¼‰
    """
    if verbose:
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±è¡¨ç¤º
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"\nğŸ“Š {model_name} ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±:")
        print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"  å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
        
        # å­¦ç¿’è¨­å®šè¡¨ç¤º
        print(f"\nâš™ï¸  {model_name} å­¦ç¿’è¨­å®š:")
        print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {num_epochs}")
        print(f"  å­¦ç¿’ç‡: {lr}")
        print(f"  æœ€é©åŒ–æ‰‹æ³•: Adam")
        print(f"  æå¤±é–¢æ•°: Binary Cross Entropy")
        print(f"  è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(train_edges)}")
        if validation_edges:
            print(f"  æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(validation_edges)}")
        print("-" * 50)
    
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.BCELoss()
    
    model.train()
    train_losses = []
    val_losses = []
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    edge_pairs = [(node_to_idx[u], node_to_idx[v]) for (u, v), _ in train_edges]
    labels = torch.tensor([label for _, label in train_edges], dtype=torch.float32)
    
    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
    val_edge_pairs = None
    val_labels = None
    if validation_edges:
        val_edge_pairs = [(node_to_idx[u], node_to_idx[v]) for (u, v), _ in validation_edges]
        val_labels = torch.tensor([label for _, label in validation_edges], dtype=torch.float32)
    
    if verbose:
        print(f"\nğŸš€ {model_name} å­¦ç¿’é–‹å§‹...")
        print("=" * 60)
    
    start_time = time.time()
    best_val_loss = float('inf')
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        
        # Training step
        optimizer.zero_grad()
        
        predictions = model(data.x, data.edge_index, data.edge_attr, edge_pairs)
        train_loss = criterion(predictions, labels)
        
        train_loss.backward()
        optimizer.step()
        
        train_losses.append(train_loss.item())
        
        # Validation step (if validation data is provided)
        val_loss = None
        if validation_edges:
            model.eval()
            with torch.no_grad():
                val_predictions = model(data.x, data.edge_index, data.edge_attr, val_edge_pairs)
                val_loss = criterion(val_predictions, val_labels).item()
                val_losses.append(val_loss)
                
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
            model.train()
        
        epoch_time = time.time() - epoch_start_time
        
        # è©³ç´°ãªé€²æ—è¡¨ç¤º
        if verbose and (epoch % 20 == 0 or epoch == num_epochs - 1):
            if val_loss is not None:
                print(f"  ğŸ“Š Epoch {epoch:3d}/{num_epochs}: "
                      f"Train Loss = {train_loss.item():.4f}, "
                      f"Val Loss = {val_loss:.4f}, "
                      f"Time = {epoch_time:.2f}s")
            else:
                print(f"  ğŸ“Š Epoch {epoch:3d}/{num_epochs}: "
                      f"Train Loss = {train_loss.item():.4f}, "
                      f"Time = {epoch_time:.2f}s")
    
    total_time = time.time() - start_time
    
    if verbose:
        print("-" * 60)
        print(f"âœ… {model_name} å­¦ç¿’å®Œäº†!")
        print(f"   ç·å­¦ç¿’æ™‚é–“: {total_time:.2f}ç§’")
        print(f"   æœ€çµ‚è¨“ç·´æå¤±: {train_losses[-1]:.4f}")
        if val_losses:
            print(f"   æœ€çµ‚æ¤œè¨¼æå¤±: {val_losses[-1]:.4f}")
            print(f"   æœ€è‰¯æ¤œè¨¼æå¤±: {best_val_loss:.4f}")
        print(f"   å¹³å‡ã‚¨ãƒãƒƒã‚¯æ™‚é–“: {total_time/num_epochs:.3f}ç§’")
    
    # å­¦ç¿’çµæœã‚’ã¾ã¨ã‚ã¦è¿”ã™
    training_info = {
        'train_losses': train_losses,
        'val_losses': val_losses if val_losses else None,
        'total_time': total_time,
        'best_val_loss': best_val_loss if val_losses else None,
        'final_train_loss': train_losses[-1],
        'model_name': model_name,
        'num_epochs': num_epochs,
        'learning_rate': lr
    }
    
    return training_info