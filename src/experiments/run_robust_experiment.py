"""
Robust Experiment å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import pickle
import random
import argparse
import yaml
import numpy as np
import torch
from torch_geometric.data import Data
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from src.preprocess.extract_edge import create_inference_only_graph, collect_attack_edges
from src.preprocess.embed_node import generate_bert_embeddings
from src.augmentation.generate_negative import (
    generate_hard_negatives,
    generate_structural_negatives,
    generate_random_negatives
)
from src.experiments.cross_validation import create_cross_validation_splits, run_cross_validation
from src.visualization.plot_results import (
    calculate_statistics,
    perform_statistical_tests,
    plot_box_plots,
    plot_bar_charts,
    plot_comprehensive_analysis,
    display_results_table,
    save_results_to_file
)


def set_seed(seed: int = 42):
    """
    ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š
    
    Args:
        seed: ã‚·ãƒ¼ãƒ‰å€¤
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)


def load_config(config_path: str) -> dict:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        config: è¨­å®šè¾æ›¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def determine_experiment_id(config: dict, args=None) -> str:
    """
    å®Ÿé¨“IDã‚’æ±ºå®šã™ã‚‹
    
    å„ªå…ˆé †ä½:
    1. ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•° (--experiment-id)
    2. YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (data.experiment_id)
    3. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§è‡ªå‹•ç”Ÿæˆ
    
    Args:
        config: è¨­å®šè¾æ›¸
        args: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        experiment_id: å®Ÿé¨“ID
    """
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒæœ€å„ªå…ˆ
    if args and hasattr(args, 'experiment_id') and args.experiment_id:
        experiment_id = args.experiment_id
        print(f"ğŸ“Œ å®Ÿé¨“IDï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ï¼‰: {experiment_id}")
        return experiment_id
    
    # æ¬¡ã«YAMLè¨­å®š
    if config['data'].get('experiment_id'):
        experiment_id = config['data']['experiment_id']
        print(f"ğŸ“Œ å®Ÿé¨“IDï¼ˆYAMLè¨­å®šï¼‰: {experiment_id}")
        return experiment_id
    
    # ã©ã¡ã‚‰ã‚‚ãªã„å ´åˆã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§è‡ªå‹•ç”Ÿæˆ
    experiment_id = f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    print(f"ğŸ“Œ å®Ÿé¨“IDï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰: {experiment_id}")
    return experiment_id


def setup_output_directory(config: dict, experiment_id: str) -> str:
    """
    å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹
    
    Args:
        config: è¨­å®šè¾æ›¸
        experiment_id: å®Ÿé¨“ID
    
    Returns:
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    """
    base_output_dir = config['data']['base_output_dir']
    output_dir = os.path.join(base_output_dir, experiment_id)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    
    return output_dir


def prepare_data(config: dict):
    """
    ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    
    Args:
        config: è¨­å®šè¾æ›¸
    
    Returns:
        tuple: (original_graph, inference_graph, attack_edges, all_nodes, 
                node_embeddings, node_to_idx, embedding_matrix, data)
    """
    print("\n" + "="*70)
    print("ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã‚’é–‹å§‹...")
    print("="*70)
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    filepath = config['data']['input_graph']
    print(f"\nğŸ“‚ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {filepath}")
    
    with open(filepath, 'rb') as f:
        original_graph = pickle.load(f)
    
    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    print("\nğŸ”— ã‚°ãƒ©ãƒ•æ§‹é€ ã®æŠ½å‡º...")
    inference_graph, inference_edges = create_inference_only_graph(original_graph)
    attack_edges = collect_attack_edges(original_graph)
    
    print(f"  Inference ã‚°ãƒ©ãƒ•: ãƒãƒ¼ãƒ‰æ•°={inference_graph.number_of_nodes()}, "
          f"ã‚¨ãƒƒã‚¸æ•°={len(inference_edges)}")
    print(f"  Attack ã‚¨ãƒƒã‚¸æ•°: {len(attack_edges)}")
    
    # å…¨ãƒãƒ¼ãƒ‰ã‚’å–å¾—
    all_nodes = sorted({n for n in original_graph.nodes()})
    print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {len(all_nodes)}")
    
    # BERTã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
    print("\nğŸ¤– BERTã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆä¸­...")
    node_embeddings = generate_bert_embeddings(all_nodes)
    
    embedding_dim = len(list(node_embeddings.values())[0])
    print(f"  ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¬¡å…ƒ: {embedding_dim}")
    
    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¡Œåˆ—ã‚’ä½œæˆ
    node_to_idx = {node: i for i, node in enumerate(all_nodes)}
    embedding_matrix = np.array([node_embeddings[node] for node in all_nodes])
    print(f"  ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¡Œåˆ—å½¢çŠ¶: {embedding_matrix.shape}")
    
    # PyTorch Geometricç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    print("\nğŸ”§ PyTorch Geometricãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ...")
    x = torch.tensor(embedding_matrix, dtype=torch.float32)
    
    edge_index = []
    edge_type = []
    
    for u, v in inference_graph.edges():
        u_idx = node_to_idx[u]
        v_idx = node_to_idx[v]
        edge_index.append([u_idx, v_idx])
        edge_type.append(0)  # inference = 0
    
    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    edge_type = torch.tensor(edge_type, dtype=torch.long)
    
    data = Data(x=x, edge_index=edge_index, edge_attr=edge_type)
    print(f"  ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿: ãƒãƒ¼ãƒ‰æ•°={data.x.size(0)}, ã‚¨ãƒƒã‚¸æ•°={data.edge_index.size(1)}")
    
    return (original_graph, inference_graph, attack_edges, all_nodes,
            node_embeddings, node_to_idx, embedding_matrix, data)


def generate_negatives(original_graph, all_nodes, attack_edges, 
                      embedding_matrix, node_to_idx, inference_graph, config):
    """
    ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    
    Args:
        original_graph: å…ƒã®ã‚°ãƒ©ãƒ•
        all_nodes: å…¨ãƒãƒ¼ãƒ‰
        attack_edges: Attackã‚¨ãƒƒã‚¸
        embedding_matrix: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¡Œåˆ—
        node_to_idx: ãƒãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°
        inference_graph: Inferenceã‚°ãƒ©ãƒ•
        config: è¨­å®šè¾æ›¸
    
    Returns:
        all_negatives: å…¨ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«
    """
    print("\n" + "="*70)
    print("ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ...")
    print("="*70)
    
    neg_config = config['negative_sampling']
    
    # Hard negatives
    hard_negatives = []
    if neg_config['hard_negatives']['enabled']:
        print("\nğŸ¯ Hard negatives ã‚’ç”Ÿæˆä¸­...")
        hard_negatives = generate_hard_negatives(
            original_graph, all_nodes, attack_edges,
            embedding_matrix, node_to_idx
        )
        print(f"  ç”Ÿæˆæ•°: {len(hard_negatives)}")
    
    # Structural negatives
    structural_negatives = []
    if neg_config['structural_negatives']['enabled']:
        print("\nğŸ—ï¸  Structural negatives ã‚’ç”Ÿæˆä¸­...")
        structural_negatives = generate_structural_negatives(
            original_graph, attack_edges, inference_graph
        )
        print(f"  ç”Ÿæˆæ•°: {len(structural_negatives)}")
    
    # Random negatives
    random_negatives = []
    if neg_config['random_negatives']['enabled']:
        print("\nğŸ² Random negatives ã‚’ç”Ÿæˆä¸­...")
        random_negatives = generate_random_negatives(
            original_graph, attack_edges, all_nodes
        )
        print(f"  ç”Ÿæˆæ•°: {len(random_negatives)}")
    
    # å…¨ã¦ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«ã‚’çµåˆ
    all_negatives = hard_negatives + structural_negatives + random_negatives
    
    print(f"\nğŸ“Š ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµæœ:")
    print(f"  Hard negatives: {len(hard_negatives)}")
    print(f"  Structural negatives: {len(structural_negatives)}")
    print(f"  Random negatives: {len(random_negatives)}")
    print(f"  Total negatives: {len(all_negatives)}")
    print(f"  Positive samples: {len(attack_edges)}")
    print(f"  Negative/Positive ratio: {len(all_negatives)/len(attack_edges):.2f}")
    
    return all_negatives


def run_robust_experiment(config_path: str, args=None):
    """
    Robust experimentã‚’å®Ÿè¡Œ
    
    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        args: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    # è¨­å®šã®èª­ã¿è¾¼ã¿
    config = load_config(config_path)
    
    # å®Ÿé¨“IDã®æ±ºå®š
    experiment_id = determine_experiment_id(config, args)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    output_dir = setup_output_directory(config, experiment_id)
    
    # è¨­å®šã‚’æ›´æ–°ï¼ˆå¾Œç¶šã®å‡¦ç†ã§ä½¿ç”¨ï¼‰
    config['data']['output_dir'] = output_dir
    config['data']['experiment_id'] = experiment_id
    
    # ã‚·ãƒ¼ãƒ‰è¨­å®š
    set_seed(config['data']['seed'])
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if config['compute']['device'] == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(config['compute']['device'])
    
    print(f"\nğŸ’» ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    (original_graph, inference_graph, attack_edges, all_nodes,
     node_embeddings, node_to_idx, embedding_matrix, data) = prepare_data(config)
    
    # ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    all_negatives = generate_negatives(
        original_graph, all_nodes, attack_edges,
        embedding_matrix, node_to_idx, inference_graph, config
    )
    
    # Cross-validationåˆ†å‰²
    print("\n" + "="*70)
    print("Cross-validationåˆ†å‰²ã‚’ä½œæˆ...")
    print("="*70)
    
    cv_splits = create_cross_validation_splits(
        attack_edges,
        all_negatives,
        n_splits=config['cross_validation']['n_folds'],
        seed=config['data']['seed']
    )
    
    print(f"\nğŸ“Š Cross-validationåˆ†å‰²çµæœ:")
    for i, (train_edges, test_edges) in enumerate(cv_splits):
        train_pos = sum(1 for _, label in train_edges if label == 1)
        train_neg = sum(1 for _, label in train_edges if label == 0)
        test_pos = sum(1 for _, label in test_edges if label == 1)
        test_neg = sum(1 for _, label in test_edges if label == 0)
        print(f"  Fold {i+1}: Train({train_pos}+, {train_neg}-), Test({test_pos}+, {test_neg}-)")
    
    # Cross-validationå®Ÿè¡Œ
    results = run_cross_validation(
        cv_splits,
        data,
        node_to_idx,
        all_nodes,
        node_embeddings,
        config,
        device=str(device)
    )
    
    # çµ±è¨ˆåˆ†æ
    print("\n" + "="*70)
    print("çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œ...")
    print("="*70)
    
    stats = calculate_statistics(results)
    test_results = perform_statistical_tests(results)
    
    # çµæœã®è¡¨ç¤º
    display_results_table(stats, test_results)
    
    # å¯è¦–åŒ–
    if config['visualization']['enabled']:
        print("\n" + "="*70)
        print("çµæœã‚’å¯è¦–åŒ–...")
        print("="*70)
        
        show_plots = config['visualization']['show_plots']
        
        if 'box_plots' in config['visualization']['plots']:
            plot_box_plots(
                results,
                save_path=os.path.join(output_dir, 'box_plots.png'),
                show_plot=show_plots
            )
        
        if 'bar_charts' in config['visualization']['plots']:
            plot_bar_charts(
                stats,
                save_path=os.path.join(output_dir, 'bar_charts.png'),
                show_plot=show_plots
            )
        
        if 'comprehensive_analysis' in config['visualization']['plots']:
            plot_comprehensive_analysis(
                results,
                save_path=os.path.join(output_dir, 'comprehensive_analysis.png'),
                show_plot=show_plots
            )
    
    # çµæœã®ä¿å­˜
    save_results_to_file(results, stats, test_results, output_dir, config)
    
    print("\n" + "="*70)
    print("âœ… å®Ÿé¨“ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    print("="*70)


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    parser = argparse.ArgumentParser(
        description='Robust Experiment for Attack Link Prediction',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿé¨“IDã‚’ä½¿ç”¨
  python src/experiments/run_robust_experiment.py
  
  # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§å®Ÿé¨“IDã‚’æŒ‡å®š
  python src/experiments/run_robust_experiment.py --experiment-id exp001
  
  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨å®Ÿé¨“IDã‚’ä¸¡æ–¹æŒ‡å®š
  python src/experiments/run_robust_experiment.py --config my_config.yaml --experiment-id exp002
        """
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config/robust_experiment.yaml',
        help='Path to configuration file (default: config/robust_experiment.yaml)'
    )
    parser.add_argument(
        '--experiment-id',
        type=str,
        default=None,
        dest='experiment_id',
        help='Experiment ID for organizing results (overrides YAML config)'
    )
    
    args = parser.parse_args()
    
    # å®Ÿé¨“å®Ÿè¡Œ
    run_robust_experiment(args.config, args)


if __name__ == '__main__':
    main()

