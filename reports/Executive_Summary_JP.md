# 実行要約：RGCNモデル vs BERTモデル比較

## 🎯 核心的発見

**RGCNモデル（AttackLinkPredictor）がBERTモデル（BERTFineTuned）を全指標で上回る結果となった。**

| 指標 | RGCN | BERT | 差分 |
|------|------|------|------|
| **Accuracy** | **85.4%** | 81.9% | **+3.5%** |
| **F1-Score** | **87.9%** | 85.8% | **+2.1%** |
| **AUC** | **91.8%** | 89.2% | **+2.6%** |

## 💡 なぜRGCNが優位なのか

### 1. **構造情報の優位性**
- グラフの推論関係（inference edges）を直接活用
- 周辺ノードとの構造的パターンを学習
- Attack関係をグラフトポロジーから効果的に予測

### 2. **ドメイン特化設計**
- ABA（Argument-based Analysis）推論に特化したアーキテクチャ
- 関係タイプ別（inference/attack）の重み学習
- 統合データセット（2,005個のattackエッジ）を効果的活用

### 3. **BERTの制約要因**
- テキストペア情報のみでグラフ構造を活用できない
- 一般ドメイン事前学習とABA特化ドメインのギャップ
- 小規模データでのファインチューニング限界

## 📊 実用的示唆

### **RGCNを選択すべき場面**
- ✅ グラフ構造が明確に定義されている
- ✅ 高精度・高信頼性が要求される
- ✅ 構造的関係性が予測の鍵となる

### **BERTを選択すべき場面**
- ✅ グラフ構造が不完全・不明確
- ✅ 見逃し（False Negative）を最小化したい
- ✅ テキスト内容の深い理解が重要

## 🔬 学術的意義

1. **構造 vs テキスト情報の価値を定量化**
2. **堅牢な実験設計**（5-fold CV + データリーケージ防止）
3. **統合データセット効果の実証**
4. **今後のGraph×NLP研究への指針提供**

## 🚀 次のステップ

### 短期改善案
- **Graph-aware BERT**の開発
- **RGCNアテンション機構**の導入
- **ハイブリッドアプローチ**の検討

### 長期展望
- **マルチモーダル統合**
- **説明可能AI統合**
- **他ドメインへの応用拡張**

---

**結論：RoomトピックのABA推論において、グラフ構造情報を直接活用するRGCNモデルが、テキスト情報主体のBERTモデルを明確に上回る性能を示した。この結果は、論証分析における構造的アプローチの重要性を実証している。**
